#
# Our FunctionBeat configuration to deploy AWS Cloudwatch Lambda JSON logs to Elasticsearch
#

# A globally unique S3 bucket is needed
functionbeat.provider.aws.endpoint: "s3.amazonaws.com"
functionbeat.provider.aws.deploy_bucket: "functionbeat-deploy.authsamples.com"

functionbeat.provider.aws.functions:
  - name: logshipper
    enabled: true
    type: cloudwatch_logs
    description: "Ships Cloudfront API Logs to ElasticCloud"

    # Functionbeat requires log groups for each individual lambda function to be listed
    # This works well enough for my demos but would be a problem in larger setups
    # https://github.com/elastic/beats/issues/10756
    triggers:
      - log_group_name: /aws/lambda/serverlessapi-deployed-getCompanyList
      - log_group_name: /aws/lambda/serverlessapi-deployed-getCompanyTransactions
      - log_group_name: /aws/lambda/serverlessapi-deployed-getUserClaims
      - log_group_name: /aws/lambda/tokenhandler-deployed-wildcard
      - log_group_name: /aws/lambda/tokenhandler-dev-wildcard

    processors:
      # Deserialize the bare JSON message field in the Cloudfront log entry into an object
      - decode_json_fields:
          fields: ["message"]
          process_array: false
          max_depth: 1
          target: ""
          overwrite_keys: true
  
setup.template.settings:
  index.number_of_shards: 1

setup.ilm.enabled: false
setup.template.name: apilogs
setup.template.pattern: apilogs-*

# Drop fields that Functionbeat adds to logs by default
processors:
  - drop_fields:
      fields: ['agent', 'ecs', 'host', 'input', 'version']

# My managed Elasticsearch instance running in AWS
output.elasticsearch:
  hosts: ["7839b30852c64538ba5682676d472abc.eu-west-1.aws.found.io:9243"]
  protocol: "https"
  api_key: "$ELASTICSEARCH_API_KEY"
  index: "apilogs-%{+yyyy.MM.dd}"
  pipelines:
    - pipeline: apilogs
